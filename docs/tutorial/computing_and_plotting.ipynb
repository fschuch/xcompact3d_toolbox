{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Computing and Plotting"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This tutorial includes an overview of the different ways available to compute, select data and plot using the xarray objects that are provided by xcompact3d-toolbox."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The very first step is to import the toolbox and other packages:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import hvplot.xarray\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import xcompact3d_toolbox as x3d"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Why xarray?\r\n",
    "\r\n",
    "The data structures are provided by [xarray](http://xarray.pydata.org/en/stable/index.html), that introduces labels in the form of dimensions, coordinates and attributes on top of raw NumPy-like arrays, which allows for a more intuitive, more concise, and less error-prone developer experience.\r\n",
    "It integrates tightly with [dask](https://dask.org/) for parallel computing.\r\n",
    "\r\n",
    "The goal here is to speed up the development of customized post-processing applications with the concise interface provided by [xarray](http://xarray.pydata.org/en/stable/index.html). Ultimately, we can compute solutions with fewer lines of code and better readability, so we expend less time testing and debugging and more time exploring our datasets and getting insights.\r\n",
    "\r\n",
    "Additionally, xcompact3d-toolbox includes extra functionalities for [DataArray](https://xcompact3d-toolbox.readthedocs.io/en/stable/Docstrings.html#xcompact3d_toolbox.array.X3dDataArray) and [Dataset](https://xcompact3d-toolbox.readthedocs.io/en/stable/Docstrings.html#xcompact3d_toolbox.array.X3dDataset).\r\n",
    "\r\n",
    "Before going forward, please, take a look at [Overview: Why xarray?](http://xarray.pydata.org/en/stable/getting-started-guide/why-xarray.html) and [Quick overview](http://xarray.pydata.org/en/stable/getting-started-guide/quick-overview.html) to understand the motivation to use [xarray](http://xarray.pydata.org/en/stable/index.html)'s data structures instead of just numpy-like arrays."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example - Flow around a cylinder"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can download the example from the [online database](https://github.com/fschuch/xcompact3d_toolbox_data), the flow around a cylinder in this case.\r\n",
    "We set `cache=True` and a local destination where it can be saved in our computer `cache_dir=\"./example/\"`, so there is no need to download it every time the kernel is restarted."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset, prm = x3d.tutorial.open_dataset(\"cylinder\", cache=True, cache_dir=\"./example/\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice there is an entire [tutorial dedicated to the parameters file](https://xcompact3d-toolbox.readthedocs.io/en/stable/tutorial/parameters.html). Now, let's take a look at the dataset:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We got a [xarray.Dataset](http://xarray.pydata.org/en/stable/generated/xarray.Dataset.html#xarray.Dataset) with the variables `u` (velocity vector), `pp` (pressure) and `epsi` (that describes the geometry), their coordinates (`x`, `y`, `t` and `i`) and some atributes like the `xcompact3d_version` used to run this simulation, the `url` where you can find the dataset and others.\r\n",
    "\r\n",
    "We can access each of variables or coordinates with the dot notation (i.g., `snapshot.pp`, `snapshot.u`, `snapshot.x`) or the dict-like notation (i.g., `snapshot[\"pp\"]`, `snapshot[\"u\"]`, `snapshot[\"x\"]`)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once the arrays are wrapped with their coordinates, we can use xarray's plotting functionality to explore our data with just a few lines of code.\r\n",
    "\r\n",
    "Starting with `epsi`, that represents the geometry (it is 1 inside the cylinder and 0 outside), we select it from the dataset and then use the method [plot](http://xarray.pydata.org/en/stable/generated/xarray.DataArray.plot.html):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset.epsi.plot()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The array in the example was two-dimensional, in this case `.plot()` automatically calls [xarray.plot.pcolormesh()](http://xarray.pydata.org/en/stable/generated/xarray.plot.pcolormesh.html#xarray.plot.pcolormesh).\r\n",
    "\r\n",
    "There are many options to customize the plots, besides that, xarray plotting functionality is a thin wrapper around the popular [matplotlib](https://matplotlib.org/) library.\r\n",
    "\r\n",
    "To improve the figure, let's set the x-axis of the plot as the coordinate `x` of our array, same for `y`. Then let's use matplotlib to set the axis aspect to `equal`. Take a look:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ax = dataset.epsi.plot(x=\"x\", y=\"y\")\r\n",
    "ax.axes.set_aspect(\"equal\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It might be important in the cylinder case to ignore the values that are inside the solid cylinder when plotting or computing any quantity.\n",
    "We can do it by preserving the values of `u` and `pp` where where `epsi` is equal to zero, and  setting the values to `np.NaN` otherwise.\n",
    "\n",
    "[xarray.Dataset.where](http://xarray.pydata.org/en/stable/generated/xarray.Dataset.where.html) is a handy method for that, take a look:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for var in [\"u\", \"pp\"]:\r\n",
    "    dataset[var] = dataset[var].where(dataset.epsi == 0.0, np.NaN)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Have you noticed that we are doing this comparison between variables with different dimensions, and it just worked? I mean, `epsi` is 2D (x, y), `pp` is 3D (x, y, t) and `u` is 4D (i, x, y, t).\n",
    "That is because xarray automatically broadcasted the values of `epsi` to each point at the coordinates `t` and `i`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Another cool feature of xarray is that we can select data based on the actual value of its coordinates, not only on the integer indexes used for selection on numpy-like arrays.\n",
    "\n",
    "To exemplify, let's [select](http://xarray.pydata.org/en/stable/generated/xarray.Dataset.sel.html) one position at the same heigh of the cylinder, but a bit downstream. Note we can get the time evolution for all variables at this specified point:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset.sel(x=10.0, y=6.0, method=\"nearest\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can chain the methods, selecting a variable, [selecting](http://xarray.pydata.org/en/stable/generated/xarray.DataArray.sel.html) a point in the domain and doing a [plot](http://xarray.pydata.org/en/stable/generated/xarray.DataArray.plot.html), all with just one line of code:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset.u.sel(x=10.0, y=6.0, method=\"nearest\").plot(x=\"t\", hue=\"i\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note this time the data was 1D, so the plot was handled internally by [xarray.plot.line](http://xarray.pydata.org/en/stable/generated/xarray.plot.line.html#xarray.plot.line)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To give you another example, let's plot the time-averaged ($60 \\le t \\le 150$) vertical velocity profile where $x=10$:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset.u.sel(x=10.0, t=slice(60.0, 150.0)).mean(\"t\").plot(y=\"y\", hue=\"i\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you saw, we can refer to the coordinates by their name when working with xarray, instead of keeping track of their axis number.\r\n",
    "\r\n",
    "To extend this concept, let's now compute the time evolution of the kinetic energy in our flow. It is given by the equation:\r\n",
    "\r\n",
    "$$\r\n",
    "k = \\int_V \\dfrac{u_iu_i}{2} dV.\r\n",
    "$$\r\n",
    "\r\n",
    "Now the code:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset[\"kinetic_energy\"] = ((dataset.u ** 2.0).sum(\"i\").x3d.simps(\"x\", \"y\")) * 0.5\r\n",
    "dataset[\"kinetic_energy\"].attrs = dict(name=\"k\", long_name=\"kinetic Energy\", units=\"-\")\r\n",
    "dataset[\"kinetic_energy\"].plot()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the code above we:\r\n",
    "\r\n",
    "* Solved the equation with a very readable code. A good point is that it worked for the `xy` planes in the dataset in this example, and all we need to do to run it in a real 3D case is include `z` at the integration;\r\n",
    "\r\n",
    "* Included attributes to describe what we just computed, making our application easier to share and collaborate. As a bonus, they were automatically included in the plot;\r\n",
    "\r\n",
    "* Plotted the results."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can use a quick [list comprehension](https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions) to get the dimensions for the volumetric integration:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "V_coords = [dim for dim in dataset.u.coords if dim in \"xyz\"]\r\n",
    "V_coords"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "and rewrite the previous example to make it more robust, now it works for 1D, 2D and 3D cases:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset[\"kinetic_energy\"] = ((dataset.u ** 2.0).sum(\"i\").x3d.simps(*V_coords)) * 0.5\r\n",
    "dataset[\"kinetic_energy\"].attrs = dict(name=\"k\", long_name=\"kinetic Energy\", units=\"-\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Going back to 2D plots, let's take the velocity vector `u`, select it for $60 \\le t \\le 150$ ([sel](http://xarray.pydata.org/en/stable/generated/xarray.DataArray.sel.html)), compute a time average ([mean](https://xarray.pydata.org/en/stable/generated/xarray.DataArray.mean.html)) and [plot](https://xarray.pydata.org/en/stable/generated/xarray.DataArray.plot.html):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "g = dataset.u.sel(t=slice(60.0, 150.0)).mean(\"t\").plot(\r\n",
    "    x=\"x\", y=\"y\", row=\"i\", cmap=\"turbo\", rasterized=True\r\n",
    ")\r\n",
    "for ax in g.axes.flat:\r\n",
    "    ax.axes.set_aspect(\"equal\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Do you want to see the time evolution? No problem. Let's take the velocity vector `u`, use [isel](https://xarray.pydata.org/en/stable/generated/xarray.DataArray.isel.html) with a [slice](https://docs.python.org/3/library/functions.html#slice) selecting every 40 points in time (otherwise we would get too many figures), and [plot](https://xarray.pydata.org/en/stable/generated/xarray.DataArray.plot.html):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "g = dataset.u.isel(t=slice(None, None, 40)).plot(\r\n",
    "    x=\"x\", y=\"y\", col=\"t\", row=\"i\", cmap=\"turbo\", rasterized=True\r\n",
    ")\r\n",
    "\r\n",
    "for ax in g.axes.flat:\r\n",
    "    ax.axes.set_aspect(\"equal\")"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To exemplify differentiation and parallel computing capabilities, let's compute the vorticity for our dataset. We just have one component for this 2D example, it is given by the equation:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "$$\n",
    "\\omega_z = \\dfrac{\\partial u_y}{\\partial x}  - \\dfrac{\\partial u_x}{\\partial y}.\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can use [xarray.DataArray.differentiate](http://xarray.pydata.org/en/stable/generated/xarray.DataArray.differentiate.html) just out of the box with its second order accurate central differences. However, we can use the 4th order accurate centered scheme available at [X3dDataArray.first_derivative](https://xcompact3d-toolbox.readthedocs.io/en/stable/Docstrings.html#xcompact3d_toolbox.array.X3dDataArray.first_derivative)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We start setting the attribute boundary conditions (`BC`) for the velocity field:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset[\"u\"].attrs[\"BC\"] = prm.get_boundary_condition(\"u\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "and then we compute the vorticity:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%time\r\n",
    "dataset[\"vort\"] = (\r\n",
    "    dataset.u.sel(i=\"y\").x3d.first_derivative(\"x\")\r\n",
    "    - dataset.u.sel(i=\"x\").x3d.first_derivative(\"y\")\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice the equation above computed the vorticity for the entire time series in our dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can use [X3dDataArray.pencil_decomp](https://xcompact3d-toolbox.readthedocs.io/en/stable/Docstrings.html#xcompact3d_toolbox.array.X3dDataArray.pencil_decomp) to coarse the velocity array to a dask array, ready for parallel computing (see [Using Dask with xarray](http://xarray.pydata.org/en/stable/user-guide/dask.html#using-dask-with-xarray)).\n",
    "Notice that [X3dDataArray.pencil_decomp](https://xcompact3d-toolbox.readthedocs.io/en/stable/Docstrings.html#xcompact3d_toolbox.array.X3dDataArray.pencil_decomp) applies `chunk=-1` for all coordinates listed in `args`, which means no decomposition, and `'auto'` to the others, delagating to dask the job of finding the optimal distribition.\n",
    "One important point here is that dask considers the dataset in this example so small that the overhead for parallel computing is not worth it. As a result, it returns with just one chunk:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "u_chunked = dataset.u.x3d.pencil_decomp(\"x\", \"y\")\r\n",
    "u_chunked"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Parallel computing is presented in this tutorial anyway, because [X3dDataArray.pencil_decomp](https://xcompact3d-toolbox.readthedocs.io/en/stable/Docstrings.html#xcompact3d_toolbox.array.X3dDataArray.pencil_decomp) returns the arrays with several chunks for datasets in real scale. Each of these chunks will be computed in parallel in multi-core systems."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Just to exemplify, let's create blocks with 51 points in time, so we can use 4 cores to compute it in parallel:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "u_chunked = dataset.u.chunk(chunks=dict(t = 51))\r\n",
    "u_chunked"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now computing the vorticity in parallel:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%time\r\n",
    "dataset[\"vort\"] = (\r\n",
    "    u_chunked.sel(i=\"y\").x3d.first_derivative(\"x\")\r\n",
    "    - u_chunked.sel(i=\"x\").x3d.first_derivative(\"y\")\r\n",
    ").compute()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Again, remember that the dataset in this tutorial is to small that the overhead for parallel computing is not worth it. The wall time was 3 times bigger, but the code is here if you plan to try it on large scale simulations."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As usual, we can set attributes to the array we just computed:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset[\"vort\"].attrs = dict(name = \"wz\", long_name=\"Vorticity\", units=\"-\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "And plot it:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "g = dataset.vort.isel(t=slice(None, None, 10)).plot(\r\n",
    "    x=\"x\", y=\"y\", col=\"t\", col_wrap=7, cmap=\"turbo\", rasterized=True, robust=True\r\n",
    ")\r\n",
    "for ax in g.axes.flat:\r\n",
    "    ax.axes.set_aspect(\"equal\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice that [xarray](http://xarray.pydata.org/en/stable/) is built on top of [Numpy](https://numpy.org/), so its arrays and datasets are compatibles with many tools of the Numpy/SciPy universe.\r\n",
    "You can even access a `numpy.ndarray` object with the property `data`:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset.epsi.data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can use it for backwards compatibility with your previous post-processing tools, in this way, the transition to xcompact3d-toolbox should be easier.\r\n",
    "It is just not so effective, because we lost track of metadata like the coordinates and attributes, they are key points for data analysis with xarray."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Interactive Visualization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-info\">\r\n",
    "\r\n",
    "For an interactive experience [launch this tutorial on Binder](https://mybinder.org/v2/gh/fschuch/xcompact3d_toolbox/main?labpath=.%2Fdocs%2Ftutorial), the widgets are not responsive when disconnected from a Python application.\r\n",
    "\r\n",
    "</div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "All the previous examples where based on matplotlib, but xarray is compatible with more options.\n",
    "One of them is [hvPlot](https://hvplot.holoviz.org/index.html) (see [Gridded Data](https://hvplot.holoviz.org/user_guide/Gridded_Data.html))."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "hvPlot is recommended when you are exploring your data and need a bit more interactivity."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To exemplify, let's reproduce one of the figure we did before, choosing one specific location in our mesh and looking at the time evolution of the velocity there:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset.u.sel(x=10.0, y=6.0, method=\"nearest\").hvplot(x=\"t\", by=\"i\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "One key aspect about hvPlot is that when it gets more coordinates than it can handle in a plot, it presents the extra coordinates in widgets. So if we do not select any specific point in the domain and reproduce the same figure above, we will get widgets to select the point where we are looking:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset.u.hvplot(x=\"t\", by=\"i\", widget_location=\"bottom\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we reproduce the time evolution of the kinect energy, this time with hvPlot:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset[\"kinetic_energy\"].hvplot()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "And one last example, we can see a really nice animation of the vorticity field, here in a Jupyter Notebook, with a very few lines of code:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset.sel(t = slice(40, None)).vort.hvplot(\r\n",
    "    x=\"x\",\r\n",
    "    y=\"y\",\r\n",
    "    aspect=\"equal\",\r\n",
    "    clim=(-5, 5),\r\n",
    "    rasterize=True,\r\n",
    "    cmap=\"turbo\",\r\n",
    "    widget_type=\"scrubber\",\r\n",
    "    widget_location=\"bottom\",\r\n",
    "    title=\"Flow around a Cylinder\",\r\n",
    "    clabel=r\"Vorticity [-]\",\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: The `sel(t = slice(40, None))` in the block above is not necessary, of course, we can see the animation since the beginning. It was just used to look better at readthedocs."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "546d5beeb22119d9a20f6c19239ae627cc2b69f70be285d1d696980c89f3c939"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('idp': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}