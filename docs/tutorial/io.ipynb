{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Reading and writing files"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This tutorial includes an overview of the different ways available to load the binary arrays from the disc after running a numerical simulation with [XCompact3d](https://github.com/xcompact3d/Incompact3d).\r\n",
    "Besides that, some options are presented to save the results from our analysis, together with some tips and tricks."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-info\">\r\n",
    "\r\n",
    "For an interactive experience [launch this tutorial on Binder](https://mybinder.org/v2/gh/fschuch/xcompact3d_toolbox/main?labpath=lab%2Ftree%2Fdocs%2Ftutorial).\r\n",
    "\r\n",
    "</div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preparation"
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we prepare the dataset for this notebook, so it can be reproduced on local machines or on the cloud, you are invited to test and interact with many of the concepts.\n",
    "It also provides nice support for courses and tutorials, let us know if you produce any of them.\n",
    "\n",
    "The very first step is to import the toolbox and other packages:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import warnings\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import xarray as xr\r\n",
    "import xcompact3d_toolbox as x3d"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we can download an example from the [online database](https://github.com/fschuch/xcompact3d_toolbox_data), the flow around a cylinder in this case.\n",
    "We set `cache=True` and a local destination where it can be saved in our computer `cache_dir=\"./example/\"`, so there is no need to download it everytime the kernel is restarted."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cylinder_ds, prm = x3d.tutorial.open_dataset(\r\n",
    "    \"cylinder\", cache=True, cache_dir=\"./example/\"\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "let's take a look at the dataset:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cylinder_ds.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We got a [xarray.Dataset](http://xarray.pydata.org/en/stable/generated/xarray.Dataset.html#xarray.Dataset) with the variables `u` (velocity vector), `pp` (pressure) and `epsi` (describes the geometry), their coordinates (`x`, `y`, `t` and `i`) and some atributes like the `xcompact3d_version` used to run this simulation, the `url` where you can find the dataset, and others.\r\n",
    "\r\n",
    "In the next block, we configure the toolbox and some atributes at the dataset, so we can write all the binary fields to the disc.\r\n",
    "Do not worry about the details right now, this is just the preparation step, we are going to discuss them later."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x3d.param[\"mytype\"] = np.float32\r\n",
    "\r\n",
    "prm.dataset.set(data_path=\"./data/\", drop_coords=\"z\")\r\n",
    "\r\n",
    "cylinder_ds.u.attrs[\"file_name\"] = \"u\"\r\n",
    "cylinder_ds.pp.attrs[\"file_name\"] = \"pp\"\r\n",
    "cylinder_ds.epsi.attrs[\"file_name\"] = \"epsilon\"\r\n",
    "\r\n",
    "prm.write(\"input.i3d\")\r\n",
    "\r\n",
    "prm.dataset.write(cylinder_ds)\r\n",
    "\r\n",
    "prm.dataset.write_xdmf(\"xy-planes.xdmf\")\r\n",
    "\r\n",
    "del cylinder_ds, prm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "After that, the files are organized as follow:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\n",
    "tutorial\n",
    "│   computing_and_plotting.ipynb\n",
    "│   io.ipynb\n",
    "│   input.i3d\n",
    "│   parameters.ipynb\n",
    "│   xy-planes.xdmf\n",
    "│\n",
    "└─── data\n",
    "│       │   epsilon.bin\n",
    "│       │   pp-000.bin\n",
    "│       │   pp-001.bin\n",
    "│       │   ... \n",
    "│       │   pp-199.bin\n",
    "│       │   pp-200.bin\n",
    "│       │   ux-000.bin\n",
    "│       │   ux-001.bin\n",
    "│       │   ... \n",
    "│       │   ux-199.bin\n",
    "│       │   ux-200.bin\n",
    "│       │   uy-000.bin\n",
    "│       │   uy-001.bin\n",
    "│       │   ... \n",
    "│       │   uy-199.bin\n",
    "│       │   uy-200.bin\n",
    "│       │   uz-000.bin\n",
    "│       │   uz-001.bin\n",
    "│       │   ... \n",
    "│       │   uz-199.bin\n",
    "│       │   uz-200.bin\n",
    "│\n",
    "└─── example\n",
    "│       │   cylinder.nc\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is very similar to what we get after successfully running a simulation, so now we can move on to the tutorial."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Why xarray?\r\n",
    "\r\n",
    "The data structures are provided by [xarray](http://xarray.pydata.org/en/stable/index.html), that introduces labels in the form of dimensions, coordinates and attributes on top of raw NumPy-like arrays, which allows for a more intuitive, more concise, and less error-prone developer experience.\r\n",
    "It integrates tightly with [dask](https://dask.org/) for parallel computing.\r\n",
    "\r\n",
    "The goal here is to speed up the development of customized post-processing applications with the concise interface provided by [xarray](http://xarray.pydata.org/en/stable/index.html). Ultimately, we can compute solutions with fewer lines of code and better readability, so we expend less time testing and debugging and more time exploring our datasets and getting insights.\r\n",
    "\r\n",
    "Additionally, xcompact3d-toolbox includes extra functionalities for [DataArray](https://xcompact3d-toolbox.readthedocs.io/en/stable/Docstrings.html#xcompact3d_toolbox.array.X3dDataArray) and [Dataset](https://xcompact3d-toolbox.readthedocs.io/en/stable/Docstrings.html#xcompact3d_toolbox.array.X3dDataset).\r\n",
    "\r\n",
    "Before going forward, please, take a look at [Overview: Why xarray?](http://xarray.pydata.org/en/stable/getting-started-guide/why-xarray.html) and [Quick overview](http://xarray.pydata.org/en/stable/getting-started-guide/quick-overview.html) to understand the motivation to use [xarray](http://xarray.pydata.org/en/stable/index.html)'s data structures instead of just numpy-like arrays."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Xarray objects on demand"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To start our post-processing, let's load the parameters file:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "prm = x3d.Parameters(loadfile=\"input.i3d\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice there is an entire [tutorial dedicated to it](https://xcompact3d-toolbox.readthedocs.io/en/stable/tutorial/parameters.html)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To save space on the disc, our dataset was converted from double precision to single, so we have to configure the toolbox to:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x3d.param[\"mytype\"] = np.float32"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The methods in the toolbox support different [filename properties](https://xcompact3d-toolbox.readthedocs.io/en/stable/Docstrings.html#xcompact3d_toolbox.io.FilenameProperties), like the classic `ux000` or the new `ux-0000.bin`, besides some combinations between them. For our case, we set the parameters as:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "prm.dataset.filename_properties.set(\r\n",
    "    separator = \"-\",\r\n",
    "    file_extension = \".bin\",\r\n",
    "    number_of_digits = 3,\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we specify the parameters for our dataset, like where it is found (`data_path`), if it needs to drop some coordinate (`drop_coords`, again, to save space, we are working with a span-wise averaged dataset, so we drop `z` to work with `xy` planes), we inform the parameter that controls the number of timesteps `snapshot_counting` and their step `snapshot_step`.\r\n",
    "Consult the [dataset documentation](https://xcompact3d-toolbox.readthedocs.io/en/stable/Docstrings.html#xcompact3d_toolbox.io.Dataset) to see different ways to customize your experience, and choose the ones that best suits your post-processing application.\r\n",
    "In this example, they are defined as:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "prm.dataset.set(\r\n",
    "    data_path=\"./data/\",\r\n",
    "    drop_coords=\"z\",\r\n",
    "    snapshot_counting=\"ilast\",\r\n",
    "    snapshot_step=\"ioutput\"\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we are good to go."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can check the [length of the dataset](https://xcompact3d-toolbox.readthedocs.io/en/stable/Docstrings.html#xcompact3d_toolbox.io.Dataset.__len__) we are dealing with:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(prm.dataset)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Meaning that our binary files range from 0 (i.g., `ux-000.bin`) to 200 (i.g., `ux-200.bin`), exactly as expected."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is possible to load any given array:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "epsilon = prm.dataset.load_array(\"./data/epsilon.bin\", add_time=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice that [load_array](https://xcompact3d-toolbox.readthedocs.io/en/stable/Docstrings.html#xcompact3d_toolbox.io.Dataset.load_array) requires the entire path to the file, and we use `add_time=False` because this array does not evolve in time like the others, i.e., it is not numerated for several snapshots.\r\n",
    "\r\n",
    "We can see it on the screen:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "epsilon"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's do it again, this time for `ux` and using `add_time=True`:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ux = prm.dataset.load_array(\"./data/ux-100.bin\", add_time=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "See that `t` is now a coordinate, and for this snapshot it was computed automatically as dimensionless time `75.0`:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ux"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "That is not all. If you have enough memory, you can load the entire time series for a given variable with [load_time_series](https://xcompact3d-toolbox.readthedocs.io/en/stable/Docstrings.html#xcompact3d_toolbox.io.Dataset.load_time_series), or simply by:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ux = prm.dataset[\"ux\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see it (note 201 files are loaded and wrapped with the appropriate coordinates):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ux"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can store each array in a different variable, like:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ux = prm.dataset[\"ux\"]\r\n",
    "uy = prm.dataset[\"uy\"]\r\n",
    "pp = prm.dataset[\"pp\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Or organize many arrays in a dataset:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# create an empty dataset\r\n",
    "ds = xr.Dataset()\r\n",
    "\r\n",
    "# populate it\r\n",
    "for var in [\"ux\", \"uy\", \"pp\"]:\r\n",
    "    ds[var] = prm.dataset[var]\r\n",
    "\r\n",
    "# show on the screen\r\n",
    "ds"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is possible to load all the variables from a given snapshot with [load_snapshot](https://xcompact3d-toolbox.readthedocs.io/en/stable/Docstrings.html#xcompact3d_toolbox.io.Dataset.load_snapshot), or simply:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "snapshot = prm.dataset[100]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "And we got a [xarray.Dataset](http://xarray.pydata.org/en/stable/generated/xarray.Dataset.html#xarray.Dataset) with all the variables and their coordinates. You can access each of them with the dot notation (i.g., `snapshot.pp`, `snapshot.ux`, `snapshot.uy`) or the dict-like notation (i.g., `snapshot[\"pp\"]`, `snapshot[\"ux\"]`, `snapshot[\"uy\"]`). See the dataset:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "snapshot"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Do you need the snapshots in a range? No problem. Let's do a slice to load the last 100, and just to exemplify, compute a time average:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "time_averaged = prm.dataset[-100:].mean(\"t\")\r\n",
    "time_averaged"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can even use the slice notation to load all the snapshots at once:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "prm.dataset[:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Of course, some simulations may not fit in the memory like in this tutorial. For these cases we can iterate over all snapshots, loading them one by one:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for ds in prm.dataset:\r\n",
    "    # Computing the vorticity, just to exemplify\r\n",
    "    vort = ds.uy.x3d.first_derivative(\"x\") - ds.ux.x3d.first_derivative(\"y\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that `reversed(prm.dataset)` also works."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Or for better control, we can iterate over a selected range of snapshots loading them one by one. The arguments are the same of a classic [range](https://docs.python.org/3/library/functions.html#func-range) in Python:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for ds in prm.dataset(100, 200, 1):\r\n",
    "    # Computing the vorticity, just to exemplify\r\n",
    "    vort = ds.uy.x3d.first_derivative(\"x\") - ds.ux.x3d.first_derivative(\"y\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Result from the last iteration\r\n",
    "vort"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Writting the results to binary files"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the last example we computed the vorticity but did nothing with it. This time, let's write it to the disc using [write](https://xcompact3d-toolbox.readthedocs.io/en/stable/Docstrings.html#xcompact3d_toolbox.io.Dataset.write):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for ds in prm.dataset:\r\n",
    "    vort = ds.uy.x3d.first_derivative(\"x\") - ds.ux.x3d.first_derivative(\"y\")\r\n",
    "    prm.dataset.write(data = vort, file_prefix = \"w3\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The example above works for a [xarray.DataArray](http://xarray.pydata.org/en/stable/generated/xarray.DataArray.html#xarray.DataArray). We can do it for a [xarray.Dataset](http://xarray.pydata.org/en/stable/generated/xarray.Dataset.html#xarray.Dataset) as well, but with one key difference. Only the arrays with an attribute called `file_name` will be written. It is done to avoid overwriting the base field (`ux`, `uy`, `uz`, ...) by accident.\r\n",
    "\r\n",
    "Let's rewrite the previous example to store `vort` in the dataset `ds`. We set an atribute `file_name` to `w3`, so the arrays will be written as `w3-000.bin`, `w3-001.bin`, `w3-002.bin`, etc.\r\n",
    "\r\n",
    "We are also suppressing warnings, because the application will tell us it can not save `pp`, `ux` and `uy`, since they do not have a `file_name`. But in fact, we do not want to rewrite them anyway.\r\n",
    "\r\n",
    "See the code:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with warnings.catch_warnings():\r\n",
    "    warnings.filterwarnings('ignore', category=UserWarning)\r\n",
    "    for ds in prm.dataset:\r\n",
    "        ds[\"vort\"] = ds.uy.x3d.first_derivative(\"x\") - ds.ux.x3d.first_derivative(\"y\")\r\n",
    "        ds[\"vort\"].attrs[\"file_name\"] = \"w3\"\r\n",
    "        prm.dataset.write(ds)"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "See the dataset from the last iteration:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ds"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The method [prm.dataset.write()](https://xcompact3d-toolbox.readthedocs.io/en/stable/Docstrings.html#xcompact3d_toolbox.io.Dataset.write) writes the files as raw binaries in the same way that [XCompact3d](https://github.com/xcompact3d/Incompact3d) would do. It means you can read them at the flow solver and also process them on any other tool that you are already familiar with, including the toolbox."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For instance, we get `w3` if we load snapshot 0 again:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "prm.dataset[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Update the xdmf file"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "After computing and writing new results to the disc, you can to open them on any external tools, like Paraview or Visit. You can update the xdmf file to include the recently computed `w3`. See the code:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "prm.dataset.write_xdmf(\"xy-planes.xdmf\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Other formats"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Xarray objects can be exported to many other formats, depending on your needs.\r\n",
    "\r\n",
    "For instance, [xarray.DataArray](http://xarray.pydata.org/en/stable/generated/xarray.DataArray.html#xarray.DataArray) and [xarray.Dataset](http://xarray.pydata.org/en/stable/generated/xarray.Dataset.html#xarray.Dataset) can be written as [netCDF](http://xarray.pydata.org/en/stable/user-guide/io.html). In this way, they will keep all dimensions, coordinates, and attributes. This format is easier to handle and share because the files are self-sufficient. It is the format used to download the dataset used in this tutorial, and it is a good alternative to use when sharing the results of your research.\r\n",
    "\r\n",
    "Just to give you an estimation about the disk usage, the size of the dataset `cylinder.nc` that we downloaded for this tutorial is 75.8 MB. The size of the folder `./data/` after producing the binary files in the same way that [XCompact3d](https://github.com/xcompact3d/Incompact3d) would do is 75.7 MB."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To exemplify the use of netCDF, let's take one snapshot:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "snapshot = prm.dataset[0]\r\n",
    "snapshot"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, let's include additional information for the ones that are going to use our data. You can set attributes for each array, coordinate, and also global attributes for the dataset. They are stored in a dictionary.\r\n",
    "\r\n",
    "See the example:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Setting attributes for each coordinate\r\n",
    "snapshot.x.attrs = dict(\r\n",
    "    name = \"x\",\r\n",
    "    long_name = \"Stream-wise coordinate\",\r\n",
    "    units = \"-\"\r\n",
    ")\r\n",
    "snapshot.y.attrs = dict(\r\n",
    "    name = \"y\",\r\n",
    "    long_name = \"Vertical coordinate\",\r\n",
    "    units = \"-\"\r\n",
    ")\r\n",
    "snapshot.t.attrs = dict(\r\n",
    "    name = \"t\",\r\n",
    "    long_name = \"Time\",\r\n",
    "    units = \"-\"\r\n",
    ")\r\n",
    "# Setting attributes for each array\r\n",
    "snapshot.ux.attrs = dict(\r\n",
    "    name = \"ux\",\r\n",
    "    long_name = \"Stream-wise velocity\",\r\n",
    "    units = \"-\"\r\n",
    ")\r\n",
    "snapshot.uy.attrs = dict(\r\n",
    "    name = \"y\",\r\n",
    "    long_name = \"Vertical velocity\",\r\n",
    "    units = \"-\"\r\n",
    ")\r\n",
    "snapshot.pp.attrs = dict(\r\n",
    "    name = \"p\",\r\n",
    "    long_name = \"Pressure\",\r\n",
    "    units = \"-\"\r\n",
    ")\r\n",
    "snapshot.w3.attrs = dict(\r\n",
    "    name = \"w3\",\r\n",
    "    long_name = \"Vorticity\",\r\n",
    "    units = \"-\"\r\n",
    ")\r\n",
    "# Setting attributes for the dataset\r\n",
    "snapshot.attrs = dict(\r\n",
    "    title = \"An example from the tutorials\",\r\n",
    "    url = \"https://xcompact3d-toolbox.readthedocs.io/en/stable/tutorial/io.html\",\r\n",
    "    authors = \"List of names\",\r\n",
    "    doi = \"maybe a fancy doi from zenodo\",\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Exporting it as a netCDF file:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "snapshot.to_netcdf(\"snapshot-000.nc\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Importing the netCDF file:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "snapshot_in = xr.open_dataset(\"snapshot-000.nc\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "See the result, it keeps all dimensions, coordinates, and attributes:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "snapshot_in"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you manage to reduce the dataset's dimensions with some integral, average, or selecting subsets of data, you can convert it to a `pandas.Dataframe` and then export it to CSV, Excel, and many other options."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For instance, let's select a vertical profile for all variables where `x = 20` and convert it to a dataframe:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "snapshot_in.sel(x=20.0).to_dataframe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, you can refer to [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/index.html) for more details."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "546d5beeb22119d9a20f6c19239ae627cc2b69f70be285d1d696980c89f3c939"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('idp': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}